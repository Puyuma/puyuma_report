\documentclass[conference]{IEEEtran}
\usepackage[english]{babel}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{url,hyperref,graphicx,float,times}
\usepackage{textcomp}
\usepackage{cite}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{placeins}
%\usepackage{flafter}

\usepackage{url}
\usepackage{listings}
% \usepackage{sectsty}
% \usepackage{authblk}
% \graphicspath{{../pdf/}{../jpeg/}}
% \DeclareGraphicsExtensions{.pdf,.jpeg,.png}

\author{
\IEEEauthorblockN{
\bf
Sheng-Wen Cheng\IEEEauthorrefmark{1},
Shao-Hua Wang\IEEEauthorrefmark{2},
Po-Sheng Chen\IEEEauthorrefmark{2},
Keng-Fu Hsu\IEEEauthorrefmark{2},
Chun-Yi He\IEEEauthorrefmark{2},
Ching-Chun (Jim) Huang\IEEEauthorrefmark{3}}

\IEEEauthorblockA{
\IEEEauthorrefmark{1}Department of Computer Science and Information Engineering,\\Providence University, Taiwan}

\IEEEauthorblockA{
\IEEEauthorrefmark{2}Department of Engineering Science,\\National Cheng Kung University, Taiwan}
    
\IEEEauthorblockA{
\IEEEauthorrefmark{3}Department of Computer Science and Information Engineering,\\National Cheng Kung University, Taiwan}
}


\begin{document}

\title{Puyuma: Linux-based RTOS experimental platform for constructing self-driving miniature vehicles}

\maketitle

\begin{abstract}
A holistic design and cost-efficient platform to construct self-driving systems is presented, with an emphasis on Linux-based software architectures for computer vision, control system, and inter-vehicle communication. Starting with an executable specification of autonomous car application, subsequent transformations are performed across different levels of abstraction until the final implementation is achieved. The software partitioning is facilitated through the integration of ROS and OpenCV in the same design environment, as well as closed-loop control algorithms and Linux in the run-time system. We built a rapid prototyping based on fundamentally open source technologies and hardware under 100 dollars USD, which allows developers to be explored and evaluated in realistic conditions efficiently. Using lane departure and the corresponding performance speedup, we show that our platform reduces the design time, while improving the verification efforts, with the aid of tweaked real-time executives.
\end{abstract}

\section{Introduction}
As an example of Autonomous vehicles, the Google Car has already succeeded in covering thousands of miles of real-road driving \cite{autonomous}.

\section{Related Work}

\section{System Architecture}

This section introduces what was integrated into our autonomous vehicle system, and how this work leverage the whole system. The overall system architecture is shown in figure \ref{fig:overall_arch}.

\FloatBarrier
\begin{figure}
	\centering
	\includegraphics[width=3in]{img/arch.png}
	\caption{System Architecture}
	\label{fig:overall_arch}
\end{figure}

\subsection{Robot Operating System(ROS)}

Robot Operating System, or ROS, is a system designed for robot. Instead a operating system, it’s a framework above operating system, proposing a identical interface around different machine architecture. As a middleware for interprocess communication, ROS takes a publish-subscribe pattern for data transfer abstraction. The implementation support multiple programming language API, enhance the system flexibility and scalability.

Moreover, ROS is an open-source collaborative platform. Developers around the world share their research across many field,like navigation, manipulation and perception. Based on this, other developers could save much cost for frastructure and concentrate on their own work.

\subsection{Hard Real-Time Operating System - Xenomai}

Real-time operating system (RTOS) guarantees the response time of real time task within specified time constraints, often referred to as “deadline”. A soft real-time OS can usually or generally meet a deadline, and a hard real-time OS can always meet a deadline deterministically. The real-time Linux extension for this project is Xenomai which provides two mechanisms, Cobalt and Mercury, to implement the real-time task. This paper just mention the Cobalt mechanism which we used for the autonomous vehicle system. Xenomai built the small extension named Cobalt into the Linux kernel,shown in figure \ref{fig:xeno_arch}, dealing with all time-critical activities, such as handling interrupts, and scheduling real-time threads. The Cobalt core has higher priority over the native Linux kernel. With the Cobalt mechanism, this project benefits from the RTOS API provided by Xenomai and abundant Linux services provided by native Linux kernel. As the above, this project also gains the portability since the real time environment is based on Linux.

\begin{figure}
	\centering
	\includegraphics[width=3in]{img/xeno_arch.png}
	\caption{Xenomai Cobalt Architecture}
	\label{fig:xeno_arch}
\end{figure}
\FloatBarrier

\subsection{Hardware}

For pursuing inexpensive and stable autonomous vehicle system, we limited the budgets within 4000 NTD, but the autonomous vehicle still has abilities of lane following, multiple car Interaction and route planning. The table \ref{hardware_list} shows the overall budgets.

\begin{table}
	\centering
	\caption{Hardware List}
	\label{hardware_list}
	\begin{tabular}{ll}
		Hardware                & Budgets  \\
		Raspberry Pi3 Model B   & 1600 NTD \\
		Raspberry Pi camera     & 698 NTD  \\
		2S LiPo battery 1300mAh & 240 NTD  \\
		Sandisk 16G microSD     & 185 NTD  \\
		L298N motor driver      & 263 NTD  \\
		Car frame               & 375 NTD  \\
		DC voltage regulator    & 105 NTD  \\
		Total                   & 3466 NTD
	\end{tabular}
\end{table}
\FloatBarrier

\section{Implementation}
\subsection{Customized Linux Kernel}

The Linux kernel is resident in memory after the booting stage, therefore the large kernel image and kernel module size may increase probability of cache miss. In order to minimize the latency effect from Linux kernel, we remove the unnecessary kernel module and file system to reduce the kernel module size. In addition, we adjust the performance related kernel configuration to ease the burden of interrupt handling.

\subsection{Software-based PWM}

Most system use pulse width modulation (PWM) to simulate the analog signal for smooth motor controlling. PWM signal was often generated by hardware, known as hardware PWM. On the contrary, using general-purpose input/output (GPIO) to simulate the PWM signal, known as software PWM.

We built the software PWM kernel module with Xenomai real-time API, named after KsoftPWM. With the real-time application, it ensures the precision of KsoftPWM signal generation. Furthermore, the KsoftPWM was built in kernel space to eliminate the system call overhead from user space.


\subsection{Lane Following Algorithm}

\subsubsection{Calibration}

Camera calibration is an early stage mission before doing the computer vision. There are two set of parameters need to be found, intrinsic parameters and extrinsic parameter. By estimate them we can know the relation between 2D image plane and 3D world.

The intrinsic matrix describes the projection from 3D world into 2D image plane. The ideal linear model is consist of focal length, pixel size and principal point. The nonlinear effect like lens distortion are also important however can not described in the linear camera model and usually solved by numerical methods. Figure \ref{fig:intrinsic} shows the effect of intrinsic calibration; The extrinsic matrix describes the translation and rotation of camera with respect to the world frame, which means the angle and position of camera taking pictures in 3D world. Applying extrinsic matrix causes ground projection, showed in Figure \ref{fig:extrinsic}, which is like a bird eye view.

\begin{figure}
	\centering
	\includegraphics[width=3.5in]{img/intrinsic.png}
	\caption{Camera Undistortion}
	\label{fig:intrinsic}
\end{figure}

\begin{figure}	
	\centering
	\includegraphics[width=2in]{img/extrinsic.png}
	\caption{Ground Projection}
	\label{fig:extrinsic}
\end{figure}
\FloatBarrier

\subsubsection{Segment Detection}

Before the pose estimation, first have to do is to detect the lane segments from the image. The lane detector can be achieved by using Canny edge detection, color thresholding method and Hough transform.

First, transform the image from RGB color space into the HSV color space then use the color thresholding method to find the interested color like yellow or white in the image. Next, use Canny edge detection to detect the edges in the image, and use the bitwise and operation on color thresholding image and Canny edge image. This is a preparation step for Hough transform. Finally, apply the Hough Line transform comes out the segments.
 
Although the lane detector can find the segments, we still need to know the side of the lane mark that the segments is on, which is much important to pose estimation. Segment side can be determined by reading multiple pixels in both positive and negative direction of the segment normal vector on color thresholded image. Figure \ref{fig:lane_detect} visualizes the segment locations and segment sides, and also shows the values of $d$ and $\phi$. The lane detector only works at the bottom ROI(Region of Interest) part because there is much possible to be the lane.

\FloatBarrier
\begin{figure}
	\centering
	\includegraphics[width=2in]{img/lane_detect.png}
	\caption{Segments visualization}
	\label{fig:lane_detect}
\end{figure}

\subsubsection{Frame Transformation}

For ease of calculation, apply extrinsic matrix that transforms the image from car's view to the road upper view  to the segments, causing a straightforward coordinate parallel to lane.
Moreover, The camera on the car is mounted in a distance from the origin. In order to know the real lateral displacement of the car, a transformation is need for converting camera frame into car frame.

\subsubsection{Pose Estimation for Single Segment}

Due to the lane geometry, each of the segment that lane detector detects can be calculated to be a single pose data with respect to the lane, $d$ is the lateral displacement and $\phi$ is the orientation angle. We will put the data into the histogram filter for data filtering later. The process is similar to vote so we call it a vote generating function.

\subsubsection{Histogram Filter}

The segment poses generated in previous process will then be voted into the histogram filter. The histogram filter will find out the mode of these datas and eliminate the data out of the mode with certain range, i.e., the noise. After that, calculate the \textbf{mean} of the rest of the datas comes out a much accurate pose information.

\subsubsection{Controller}We build a differential wheeled car, on which there are two independent motors. The car can be turn by changing the speed rate between two motors, hence it does not require any additional steering mechanics.
	We use the well known algorithm \textbf{"PID controller"} to fix the orientation and lateral displacement.

The equation of PID controller in continuous time is given as:

\[e(t) = setpoint(t) - x(t)\]

\[u(t) = K_p e(t) + K_i \int_{0}^{t} e(\tau) d\tau + K_d  \frac{de(t)}{dt}\]

and for discrete time:

\[e[t] = setpoint[t] - x[t]\]

\[u[t] = K_p e[t] + K_i \sum_0^t e[t] \Delta t + K_d \frac{e[t] - e[t-1]}{\Delta t}\]

	The pose controller is a cascaded PID controller.The $\phi$ controller is a low level controller for lane orientation stabilizing, and d controller fix the lateral displacement by changing the setpoint of $\phi$ controller to turn left or right.
The wheel control signal (PWM) is simply the throttle value plus the correction value:

\begin{lstlisting}
pwm_left = THROTTLE__BASE - pwm_correction
pwm_right = THROTTLE__BASE + pwm_correction
\end{lstlisting}

\FloatBarrier
\begin{figure}	
	\centering
	\includegraphics[width=3.5in]{img/controller.png}
	\caption{Control Diagram}
	\label{fig:controller}
\end{figure}

\subsection{Multiple Car Interaction}

\subsubsection{Apriltag}

Apriltag is a visual fiducial system. It appears as 2D bar code and stores data like QRcode. The difference is that Apriltag contains less data but provides farther and clearer data fetching, regardless of the orientation of view. Thus, it is useful for a wide variety of tasks including augmented reality, robotics, and camera calibration. The AprilTag detection software computes the precise 3D position, orientation, and identity of the tags relative to the camera. The 36h11 Apriltag family is adopted in this project to simulate scenario, like intersections, bus stops, traffic signal and parking lot.

\subsubsection{Crossroad}

Instead of using traditional and inefficient traffic light, we implement central management toward city crossroads. Before crossing a intersection, cars send request to the server according to the apriltag nearby which determines the crossroad ID. We predefine several states when multiple car intend to pass through the crossroad. For some situation, cars can pass at the same time, and others cannot, whereas need to set a lock until one car leaves 	the crossroad.

\section{Performance}

Based on the works mentioned above, this section we present some experimental results that quantify the performance of the system real time ability on stressed environment. In addition, we measure three kinds of tasks which were executed in user space, kernel space and irq task, respectively. We also compare performance of KsoftPWM, non-real-time PWM kernel module (nRTPKM) and WiringPi, the most famous library for GPIO controlling on Raspberry Pi.

	The measurement were obtained using Raspberry Pi 3 with 1.2GHz ARM Cortex-A53 CPU on a Broadcom bcm2709 chip, and the system load was generated by Linux Test Project (LTP). Linux Test Project provides a collection of tools for validating the reliability, robustness, and stability of Linux. Unit of latency is microsecond in all measurement.

\FloatBarrier
\begin{figure}	
	\centering
	\includegraphics[width=2in]{img/stock_kernel.png}
	\caption{Stock Kernel Performance}
	\label{fig:stock_kernel_perf}
\end{figure}

\begin{figure}	
	\centering
	\includegraphics[width=2in]{img/xenomai_load.png}
	\caption{Xenomai Performance}
	\label{fig:xeno_perf}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=2in]{img/xenomai_load_modify.png}
	\caption{Customized Xenomai Performance}
	\label{fig:xeno_perf_modify}
\end{figure}

\begin{table}[]
\centering
\caption{Maximum latency for Xenomai}
\label{xeno_compare}
\begin{tabular}{llll}
                              & User task & Kernel task & Irq task \\
Xenomai with original kernel  & 76.067 us & 36.262 us   & 27.895us \\
Xenomai with customized kernel & 42.678us  & 29.973us    & 27.11us 
\end{tabular}
\end{table}

\subsection{System Real-Time Performance}

Real-time performance is measured by stressing the system with LTP and applying cyclictest. We use LTP $-i$ and $-c$ flags to present the background CPU load with multiple processes and accessing on IO bus. Figure \ref{fig:stock_kernel_perf} shows the latency distribution in stock kernel. In contrast, measurement in Xenomai environment, shown in figure \ref{fig:xeno_perf}, obviously, Xenomai provides much better real-time performance. The customized kernel present better real-time ability in the user and kernel space, shown in figure \ref{fig:xeno_perf_modify}. Table \ref{xeno_compare} records the maximum latency for Xenomai in both original and customized kernel.

\subsection{KsoftPWM}

The KsoftPWM performs better real-time ability than the others, shown in figure \ref{fig:ksoftpwm_perf}. The WiringPi real-time ability is similar to nRTPKM, since both of them are not in Xenomai environment and perform like the stock kernel. The difference of minimum latency between WiringPi and nRTPKM was caused by different implementation. nRTPKM uses sleep function to simulate the PWM signal, and WiringPi uses busy-waiting delay function to implement which may cause higher system load.

\FloatBarrier

\begin{figure}
	\centering
	\includegraphics[width=2in]{img/ksoftpwm_load.png}
	\caption{PWM Task Performance}
	\label{fig:ksoftpwm_perf}
\end{figure}

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
