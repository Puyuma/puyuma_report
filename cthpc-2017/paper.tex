\documentclass[conference]{IEEEtran}
\usepackage[english]{babel}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{url,hyperref,graphicx,float,times}
\usepackage{textcomp}
\usepackage{cite}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{placeins}
%\usepackage{flafter}

\usepackage{url}
\usepackage{listings}
% \usepackage{sectsty}
% \usepackage{authblk}
% \graphicspath{{../pdf/}{../jpeg/}}
% \DeclareGraphicsExtensions{.pdf,.jpeg,.png}

\author{
\IEEEauthorblockN{
\bf
Sheng-Wen Cheng\IEEEauthorrefmark{1},
Shao-Hua Wang\IEEEauthorrefmark{2},
Po-Sheng Chen\IEEEauthorrefmark{2},
Keng-Fu Hsu\IEEEauthorrefmark{2},
Chun-Yi He\IEEEauthorrefmark{2},
Ching-Chun (Jim) Huang\IEEEauthorrefmark{3}}

\IEEEauthorblockA{
\IEEEauthorrefmark{1}Department of Computer Science and Information Engineering, Providence University, Taiwan}

\IEEEauthorblockA{
\IEEEauthorrefmark{2}Department of Engineering Science, National Cheng Kung University, Taiwan}
    
\IEEEauthorblockA{
\IEEEauthorrefmark{3}Department of Computer Science and Information Engineering, National Cheng Kung University, Taiwan}
}


\begin{document}

\title{Puyuma: Linux-based RTOS experimental platform for constructing self-driving miniature vehicles}

\maketitle

\begin{abstract}
A holistic design and cost-efficient platform to construct self-driving systems is presented, with an emphasis on Linux-based software architectures for computer vision, control system, and inter-vehicle communication. Starting with an executable specification of autonomous car application, subsequent transformations are performed across different levels of abstraction until the final implementation is achieved. The software partitioning is facilitated through the integration of ROS and OpenCV in the same design environment, as well as closed-loop control algorithms and Linux in the run-time system. We built a rapid prototyping based on fundamentally open source technologies and hardware under 100 dollars USD, which allows developers to be explored and evaluated in realistic conditions efficiently. Using lane departure and the corresponding performance speedup, we show that our platform reduces the design time, while improving the verification efforts, with the aid of tweaked real-time executives.
\end{abstract}

\section{Introduction}
As an example of autonomous vehicles, the Google Car has already succeeded in covering thousands of miles of real-road driving \cite{autonomous} with the promising benefits by increasing traffic efficiency \cite{traffic-flow}, reducing pollution \cite{reduce-pollution}, and eliminating up to 90\% of traffic accidents \cite{traffic-accident}. However, it is not straightforward for most people to build autonomous vehicles due to very high bill of materials (BOM) and insufficient system software infrastructure, that prevents from potential innovations and collobrations, especially to arising maker movement \cite{maker}.

The goal of this research was to adapt open source foundation and to design algorithms for a self-driving miniature vehicle, which should be able to reliably follow lane markings, overtake stationary obstacles, and park automatically for inexpensive hardware configurations. We explicitly explore the possibility to not only exploit hardware components but also the software/hardware interface to read data from sensors and to control the actors for steering and acceleration, which was evaluated by various system services of the incorporation of the real-time extension for GNU/Linux. Afterwards, a short overview of the development process and the evaluation of the software is presented.

\section{Related Work}

In this section, we concentrate on currently available frameworks for the development of component-based embedded automotive and robotics software.

In 2016, MIT CSAIL took students on a trip to "Duckietown" \cite{Duckietown} to create self-driving taxis that can navigate the roads of a model city with just a single on-board camera and no pre-programmed maps. Students developed algorithms to read traffic signs and notice pedestrian-ducks, and learned to integrate different disciplines like control theory, machine learning, and computer vision into their systems. Eventually, MIT distributes all the lecture materials, middleware, drivers, ROS modules, and etc. as open source software.

AUTOSAR (AUTomotive Open System ARchitecture) is a standardized architecture for automotive software systems. Its primary focus is the system development process for electronic control units (ECU) and does not provide specific support for sensor/actuator-based autonomou ssystem development \cite{rtes}. An implementation of an AUTOSAR-compliant embedded software platform is Arctic Core \cite{arctic-core}, offering a real-time operating system, memory services, and communication services such as CAN and LIN.

In recent years, the Robot Operating System (ROS) \cite{ROS} incorporates the simulationenvironment Player/Stage/Gazebo \cite{player/stage}, and it has been widely adopted as a meta-OS for many popular robotic platforms. The abstraction of physical sensors and actuators enables ROS to support a wide range of robotics platform and reuse of components by implementing publish-subscribe design pattern for inter-component communications.

\section{System Architecture}

The system is designed for multiple self-driving cars, enabling collaborative computer vision, map navigation, motor control, and wireless communications, shown in Figure \ref{fig:overall_arch}. It aggregates local pose graphs obtained from its multiple cars into a global pose graph, which it then feeds back to the cars to increase their mapping and localization effectiveness.

\FloatBarrier

\begin{figure}
	\centering
	\includegraphics[width=2.3in]{img/soft_arch.jpg}
	\caption{System Architecture}
	\label{fig:overall_arch}
\end{figure}

\subsection{Hardware}

Despite limited the budget shown in table \ref{hardware_list}, our autonomous vehicle prototype still has abilities of lane following, multiple car Interaction and route planning.

\begin{table}
	\centering
	\caption{Bill Of Materials}
	\label{hardware_list}
	\begin{tabular}{ll}
		Hardware                & Budgets  \\
		Raspberry Pi3 Model B   & 1200 NTD \\
		Raspberry Pi camera     & 698 NTD  \\
		2S LiPo battery 1300mAh & 240 NTD  \\
		Sandisk 16G microSD     & 185 NTD  \\
		L298N motor driver      & 263 NTD  \\
		Car frame               & 375 NTD  \\
		DC voltage regulator    & 105 NTD  \\
		Total                   & 3066 NTD
	\end{tabular}
\end{table}

\section{Implementation}

\subsection{Hard Real-Time Operating System}

RTOS guarantees the response time of real time task within specified time constraints \cite{RTOS}, often referred to as "deadline", and a hard real-time OS can always meet a deadline deterministically. We adopt Xenomai \cite{Xenomai}, an open source real-time Linux extension, allowing periodic preemptive hard real-time tasks along with typical Linux kernel and userspace. The Cobalt core in Xenomai 3 is a co-kernel which supplements the Linux kernel for delivering real-time services with very low latency \cite{rtlws2015}, shown in Figure \ref{fig:xeno_arch}, dealing with all time-critical events, such as interrupt handling, and scheduling real-time threads. Cobalt core, thereby has higher priority over Linux kernel. Our self-driving car benefits from deterministic behavior in Xenomai 3.

\FloatBarrier
\begin{figure}
	\centering
	\includegraphics[width=3in]{img/xeno_arch.jpg}
	\caption{Cobalt core in Xenomai 3}
	\label{fig:xeno_arch}
\end{figure}

Most system use pulse width modulation (PWM) to simulate the analog signal for smooth motor controlling. PWM signals are often generated by certain hardware. On the contrary, using general-purpose input/output (GPIO) to simulate PWM signals is known as software PWM. We implement the later as a Xenomai kernel-mode real-time task to ensure the precision of PWM signal generation, named after KsoftPWM, for closed-loop control system, benefiting from the limination of system call overhead and potential locks.

\subsection{Lane Following Algorithm}

Lane following algorithm is the core of the Puyuma, it consists the lane detector algorithm and self-driving algorithm. Lane detector algorithm provides pose information for the unmanned vehicle. The pose information contains lateral displacement and orientation of car.

We refer to MIT Duckietown's experience \cite{Duckietown} and created an artificial environment that the lane detector can be implemented easier. The lane detector detects segments from image, and identifies the lane by using several computer vision techniques like Canny edge detection, HSV color thresholding and Hough transform.

We first cut out the sub-region from original image to increase the accuracy and using Homography Transform to change the camera view. After that, we use lane detector to detects the segments and calculate lane pose due to the lane geometry. Histogram filter is also used to make the prediction better. 

After finished implementing the lane detector, we use the \textbf{PID Controller} algorithm to make the car smoothly driving on the road.

\begin{figure}
	\centering
	\includegraphics[width=3in]{img/lane_flow.png}
	\caption{lane following algorithm work flow}
	\label{fig:lane_following_flow}
\end{figure}

\subsubsection{Calibration}

The camera was calibrated before activating the controller. Two parameters are used to describe the relationship between image and real world: intrinsic matrix and extrinsic matrix.

The intrinsic matrix is also refer to the camera projection, it is an ideal linear model consists of focal length, pixel size and principal point, the non-linear effects like lens distortion[\ref{fig:intrinsic}] are usually solved numerically.

The extrinsic matrix represents the rotation and translation of camera with respect to the world. A linear transformation called Homograpy is applied on  the matrix to change the camera view purely mathematically.

Figure \ref{fig:extrinsic} show the result of Homography transformation, we exploit the transformation for the lane detectoion algorithm, the result is usually called the bird view image or inverse perspective mapping.

\begin{figure}
	\centering
	\includegraphics[width=3.5in]{img/intrinsic.png}
	\caption{Camera undistortion}
	\label{fig:intrinsic}
\end{figure}

\begin{figure}	
	\centering
	\includegraphics[width=2in]{img/extrinsic.png}
	\caption{Homography transformation (ground projection)}
	\label{fig:extrinsic}
\end{figure}

\subsubsection{Segment Detection}

The lane segment detection is performed before pose estimation. We first cut out the bottom half image, and we called this the Region of Interest (ROI). The reason we only left with ROI is because lane segments have much more chance to locate there due to the camera projection. We then use Canny edge detection for contour finding, HSV color thresholding to search for specified color region and Hough transform to detect for straight lines.

Figure \ref{fig:lane_detect} visualizes the lane pose and segments on the ROI region.

\begin{figure}
	\centering
	\includegraphics[width=2in]{img/lane_detect.png}
	\caption{Segments visualization}
	\label{fig:lane_detect}
\end{figure}

\subsubsection{Lane detector work conditions}
$ $
\begin{table}[!htbp]
	\centering
	\caption{Lane detector work conditions}
	\label{lane_detector_condition}
	\begin{tabular}{ll}
		Frame rate                      &10fps \\
		Image format                    &8-bits RGB cv::Mat \\
		Image size                      &320x240 px	 \\	
		ROI (Region of Interest) size   &320x120 px
	\end{tabular}
\end{table}

\subsubsection{Pose Estimation}

After detecting the lines, we can generate lane pose for every segments according to the lane geometry. The lane pose $d$ and $phi$ represent the car lateral displacement and orientation angle. we later feed the poses into the histogram filter for a better prediction of the lane pose.

\subsubsection{Histogram Filter}

The histogram filter works like a vote box. We first filter out extreme value by finding the \textbf{mode}, then calculate the \textbf{mean} of the rest of the data. Higher vote pose will have higher chance to dominate the result.

\subsubsection{Controller}

Puyuma is a differential wheeled type car. There are two independent motors on two side. The car can be turned by changing the speed rate between two motors, therefore, it does not requires any steering mechanics. We use the \textbf{PID Control} algorithm to fix the orientation and lateral displacement.

The pose controller is a cascaded PID controller. The $\phi$ controller is a low level controller for lane orientation stabilizing, and d controller fix the lateral displacement by changing the setpoint of $\phi$ controller to turn left or right.

\begin{figure}	
	\centering
	\includegraphics[width=3.5in]{img/controller.png}
	\caption{Control Diagram}
	\label{fig:controller}
\end{figure}

\section{Performance}

We executed tasks in user space, kernel space and irq task respectively, to evaluate real-time capability. We also compare performance among KsoftPWM, non-real-time PWM kernel module (nRTPKM) and WiringPi \cite{WiringPi}, the most famous library for GPIO controlling on Raspberry Pi 3 (Broadcom bcm2709 SoC, 1.2GHz ARM Cortex-A53 CPU). The background system load was generated by Linux Test Project (LTP), which provides a collection of tools for validating the reliability, robustness, and stability of Linux. Unit of latency is microsecond in all measurement.

\begin{figure}	
	\centering
	\includegraphics[width=2in]{img/xenomai_load.png}
	\caption{Xenomai Performance}
	\label{fig:xeno_perf}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=2in]{img/xenomai_load_modify.png}
	\caption{Customized Xenomai Performance}
	\label{fig:xeno_perf_modify}
\end{figure}

\begin{table}[]
\centering
\caption{Maximum latency for Xenomai}
\label{xeno_compare}
\begin{tabular}{llll}
                              & User task & Kernel task & Irq task \\
Xenomai with original kernel  & 76.067 us & 36.262 us   & 27.895us \\
Xenomai with customized kernel & 42.678us  & 29.973us    & 27.11us 
\end{tabular}
\end{table}

\subsection{System Real-Time Performance}

Real-time performance is measured by stressing the system with LTP and applying cyclictest. We use LTP $-i$ and $-c$ flags to specify the background CPU load with multiple processes and accessing on IO bus. Our customized Linux kernel brings better real-time ability in both user and kernel space, shown in Figure \ref{fig:xeno_perf_modify}. Table \ref{xeno_compare} records the maximum latency for Xenomai.

\subsection{KsoftPWM}

The KsoftPWM outperforms in better real-time ability, shown in Figure \ref{fig:ksoftpwm_perf}. The latency distribution of WiringPi is similar to nRTPKM, since both of them are just normal Linux userspace tasks rather than hard real-time one. The difference of minimum latency between WiringPi and nRTPKM was caused by different implementation. nRTPKM uses sleep function to simulate the PWM signals while WiringPi uses busy-waiting delay which may cause higher system load.

\begin{figure}
	\centering
	\includegraphics[width=2in]{img/ksoftpwm_load.png}
	\caption{PWM Task Performance}
	\label{fig:ksoftpwm_perf}
\end{figure}

\section{Conclusion}

This paper presents the hardware and software architecture of a self-driving miniature vehicle based entirely on cost-efficient components, that implies strategic values for the long term evaluation. RTOS should be very efficient in terms of resource usage and runtime. The context switching performance is important because the number of sensors can be high and we need to read data from different sensors continuously in real-time. Linux with real-time extension  fulfills all these criteria e.g., performance, reusability, changeability, and maintainability, which have significant value from the software engineer's perspective. Puyuma is released as an open source project as well as ROS, allowing further collaboration on algorithms and system integration.

\section{Acknowledge}

We would like to express our deep gratitude to Professor Nick Wang of National Chao Tung University in Taiwan for his enthusiastic encouragement on Duckietown lecture.

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
